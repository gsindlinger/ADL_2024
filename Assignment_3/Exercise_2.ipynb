{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 2000 samples.\n",
      "Variation types:  [733, 147, 120]\n",
      "[('ac', 0), ('aaaaaabbbbbbcccccc', 1), ('bab', 0), ('bacb', 0), ('aabbcc', 1)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_correct_sample(max_length=20):\n",
    "    n = random.randint(1, np.ceil(max_length / 3))\n",
    "    return ('a' * n) + ('b' * n) + ('c' * n)\n",
    "\n",
    "def create_dataset(num_samples, max_length=20):\n",
    "    dataset = []\n",
    "    \n",
    "    # Generate samples of the form a^n b^n c^n\n",
    "    while len(dataset) < num_samples:\n",
    "        sample = generate_correct_sample(max_length)\n",
    "        if len(sample) < max_length + 1:\n",
    "            dataset.append((sample, 1))\n",
    "        \n",
    "    # Generate counterexamples with slight variations\n",
    "    count_variations = [0,0,0]\n",
    "    while len(dataset) < 2 * num_samples:\n",
    "        probabilities = [0.7, 0.15, 0.15]\n",
    "        variation_type = np.random.choice([0, 1, 2], p=probabilities)\n",
    "        # Count the number of variations of each type\n",
    "        if variation_type == 0:\n",
    "            # Generate counterexample by n randomly selected characters\n",
    "            n = random.randint(1, np.ceil(max_length / 3))\n",
    "            chars = random.choices(['a', 'b', 'c'], k=n)\n",
    "            counter_example = ''.join(chars)\n",
    "        elif variation_type == 1:\n",
    "            # Remove one character from the sample\n",
    "            sample = generate_correct_sample(max_length)\n",
    "            idx = random.randint(0, len(sample) - 1)\n",
    "            counter_example = sample[:idx] + sample[idx+1:]\n",
    "        else:\n",
    "            # Add one character to the sample\n",
    "            sample = generate_correct_sample(max_length)\n",
    "            idx = random.randint(0, len(sample) - 1)\n",
    "            counter_example = sample[:idx] + random.choice(['a', 'b', 'c']) + sample[idx:]\n",
    "            \n",
    "        # Check whether counter example isnt randomly a correct sample\n",
    "        counter = Counter(counter_example)\n",
    "        if counter['a'] == counter['b'] == counter['c']:\n",
    "            continue\n",
    "        \n",
    "        # Check if the counterexample is not too long\n",
    "        if len(counter_example) < 21:\n",
    "            count_variations[variation_type] += 1\n",
    "            dataset.append((counter_example, 0))  # Append the counterexample along with its label 0\n",
    "       \n",
    "    # Shuffle the dataset \n",
    "    random.shuffle(dataset)\n",
    "    print(\"Dataset created with {} samples.\".format(len(dataset)))\n",
    "    print(\"Variation types: \", count_variations)\n",
    "    assert np.sum(count_variations) == len(dataset) / 2\n",
    "    return dataset\n",
    "\n",
    "# Example usage:\n",
    "num_samples = 1000\n",
    "max_length = 20\n",
    "dataset = create_dataset(num_samples, max_length)\n",
    "print(dataset[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 20000 samples.\n",
      "Variation types:  [7031, 1602, 1367]\n",
      "(tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.]]), tensor(1.))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# define char to index mapping\n",
    "char_to_index = {'a': 0, 'b': 1, 'c': 2, 'p': 3}\n",
    "\n",
    "def char_to_one_hot(char, num_classes=3):\n",
    "    index = char_to_index[char]\n",
    "    one_hot = np.zeros(num_classes)\n",
    "    one_hot[index] = 1\n",
    "    return one_hot\n",
    "\n",
    "def string_to_tensor(string, padding_length=0, add_padding = False):\n",
    "    if add_padding:\n",
    "        tensor = np.array([char_to_one_hot(char, num_classes=4) for char in string]\n",
    "                          + [char_to_one_hot('p', num_classes=4)] * (padding_length - len(string)))\n",
    "    else:\n",
    "        tensor = np.array([char_to_one_hot(char) for char in string])\n",
    "    return torch.tensor(tensor, dtype=torch.float32)\n",
    "\n",
    "class GrammarDataset(Dataset):\n",
    "    def __init__(self, data, padding_length=0, add_padding = False):\n",
    "        self.data = data\n",
    "        self.add_padding = add_padding\n",
    "        self.padding_length = padding_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        string, label = self.data[idx]\n",
    "        input_tensor = string_to_tensor(string, padding_length=self.padding_length, add_padding=self.add_padding)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "        return input_tensor, label_tensor\n",
    "\n",
    "# Example usage\n",
    "dataset = create_dataset(10000, max_length=20)\n",
    "add_padding = True\n",
    "if add_padding:\n",
    "    grammar_dataset = GrammarDataset(dataset, padding_length=20, add_padding=True)\n",
    "else:\n",
    "    grammar_dataset = GrammarDataset(dataset)\n",
    "\n",
    "#print example\n",
    "print(grammar_dataset[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(0)    \n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # Initial hidden state\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])  # Get the output from the last time step\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Training loop method\n",
    "def train_model(model, criterion, optimizer, num_epochs, dataset, batch_size=1):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.squeeze(0), labels.unsqueeze(0)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(data_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, batch_size=1):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in DataLoader(dataset, batch_size):\n",
    "            inputs, labels = inputs.squeeze(0), labels.unsqueeze(0)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            outputs = outputs.squeeze()\n",
    "            labels = labels.squeeze()\n",
    "            assert labels.size() == outputs.size()\n",
    "            \n",
    "            predicted = (outputs > 0.5).float()\n",
    "            \n",
    "            if labels.size() == torch.Size([]):\n",
    "                total += 1\n",
    "                correct += (predicted == labels).item()\n",
    "            else:\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 2000 samples.\n",
      "Variation types:  [721, 155, 124]\n"
     ]
    }
   ],
   "source": [
    "## Create the dataset and use it for all models\n",
    "dataset = create_dataset(1000, max_length=20)\n",
    "\n",
    "# With padding\n",
    "grammar_dataset_padded = GrammarDataset(dataset, padding_length=20, add_padding=True)\n",
    "\n",
    "# Without padding\n",
    "grammar_dataset = GrammarDataset(dataset)\n",
    "\n",
    "# Train and test splits\n",
    "train_size = int(0.8 * len(grammar_dataset))\n",
    "test_size = len(grammar_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(grammar_dataset, [train_size, test_size])\n",
    "\n",
    "train_size_padded = int(0.8 * len(grammar_dataset_padded))\n",
    "test_size_padded = len(grammar_dataset_padded) - train_size_padded\n",
    "train_dataset_padded, test_dataset_padded = torch.utils.data.random_split(grammar_dataset_padded, [train_size_padded, test_size_padded])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6385653500258922\n",
      "Epoch [2/10], Loss: 0.5237812813464552\n",
      "Epoch [3/10], Loss: 0.48006012875121085\n",
      "Epoch [4/10], Loss: 0.46463105104165153\n",
      "Epoch [5/10], Loss: 0.45482728651259097\n",
      "Epoch [6/10], Loss: 0.4469174789043609\n",
      "Epoch [7/10], Loss: 0.43487689760164355\n",
      "Epoch [8/10], Loss: 0.4238006698561367\n",
      "Epoch [9/10], Loss: 0.41492007648863366\n",
      "Epoch [10/10], Loss: 0.40758682242012584\n",
      "Accuracy: 78.75%\n",
      "Input: aaabbbccc, Label: 1, Predicted: 0.773736834526062\n",
      "Input: aabbcc, Label: 1, Predicted: 0.7239737510681152\n",
      "Input: cacbb, Label: 0, Predicted: 0.012911645695567131\n",
      "Input: aabbcc, Label: 1, Predicted: 0.7239737510681152\n",
      "Input: ba, Label: 0, Predicted: 0.0513872355222702\n",
      "Input: aaaaaaabbbbbbccccccc, Label: 0, Predicted: 0.7920834422111511\n",
      "Input: aaaaaabbbbbbcccccc, Label: 1, Predicted: 0.7918806672096252\n",
      "Input: aaaaaabbbbbbcccccc, Label: 1, Predicted: 0.7918806672096252\n",
      "Input: aaabbbccc, Label: 1, Predicted: 0.773736834526062\n",
      "Input: aaaaaabbbbbbcccccc, Label: 1, Predicted: 0.7918806672096252\n",
      "Input: abbc, Predicted: 0.5838593244552612\n"
     ]
    }
   ],
   "source": [
    "# Run without padding\n",
    "add_padding = False\n",
    "batch_size = 1\n",
    "input_size = 3\n",
    "\n",
    "# model definition\n",
    "model = RNNClassifier(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "train_model(model, criterion, optimizer, num_epochs, train_dataset, batch_size)    \n",
    "accuracy = evaluate(model, test_dataset, batch_size)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        inputs, labels = test_dataset[i]\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        outputs = model(inputs)\n",
    "        predicted = outputs\n",
    "        inputs_str = ''.join(['a' if c[0] == 1 else 'b' if c[1] == 1 else 'c' if c[2] == 1 else '' for c in inputs[0]])\n",
    "        print(f'Input: {inputs_str}, Label: {int(labels.item())}, Predicted: {predicted.item()}')\n",
    "        \n",
    "        \n",
    "# Test 'abbc' as input\n",
    "inputs = string_to_tensor('abbc')\n",
    "inputs = inputs.unsqueeze(0)\n",
    "outputs = model(inputs)\n",
    "predicted = outputs\n",
    "inputs_str = ''.join(['a' if c[0] == 1 else 'b' if c[1] == 1 else 'c' if c[2] == 1 else '' for c in inputs[0]])\n",
    "print(f'Input: {inputs_str}, Predicted: {predicted.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.697312206029892\n",
      "Epoch [2/10], Loss: 0.6938045907020569\n",
      "Epoch [3/10], Loss: 0.6923642420768737\n",
      "Epoch [4/10], Loss: 0.6920537102222443\n",
      "Epoch [5/10], Loss: 0.6913264262676239\n",
      "Epoch [6/10], Loss: 0.6906245183944703\n",
      "Epoch [7/10], Loss: 0.6899545621871949\n",
      "Epoch [8/10], Loss: 0.688954520225525\n",
      "Epoch [9/10], Loss: 0.6876797449588775\n",
      "Epoch [10/10], Loss: 0.6860293436050415\n",
      "Accuracy: 58.50%\n",
      "Input: aaaaabbbbbbcccccc, Label: 0, Predicted: 0.4934021830558777\n",
      "Input: cabbb, Label: 0, Predicted: 0.4928710460662842\n",
      "Input: bbca, Label: 0, Predicted: 0.4928710460662842\n",
      "Input: b, Label: 0, Predicted: 0.4928710460662842\n",
      "Input: aaaaaabbbbbbcccccc, Label: 1, Predicted: 0.5295969843864441\n",
      "Input: aaaaaabbbbbbcccccc, Label: 1, Predicted: 0.5295969843864441\n",
      "Input: aaaaaa, Label: 0, Predicted: 0.4928710460662842\n",
      "Input: aabbc, Label: 0, Predicted: 0.49287116527557373\n",
      "Input: aaaaabbbbbccccc, Label: 1, Predicted: 0.49431759119033813\n",
      "Input: aaaabbbbcccc, Label: 1, Predicted: 0.4929177165031433\n"
     ]
    }
   ],
   "source": [
    "# With Padding\n",
    "add_padding = True\n",
    "batch_size = 32\n",
    "input_size = 4\n",
    "\n",
    "model = RNNClassifier(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "train_model(model, criterion, optimizer, num_epochs, train_dataset_padded, batch_size)\n",
    "accuracy = evaluate(model, test_dataset_padded, batch_size)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        inputs, labels = test_dataset_padded[i]\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        outputs = model(inputs)\n",
    "        predicted = outputs\n",
    "        inputs_str = ''.join(['a' if c[0] == 1 else 'b' if c[1] == 1 else 'c' if c[2] == 1 else '' for c in inputs[0]])\n",
    "        print(f'Input: {inputs_str}, Label: {int(labels.item())}, Predicted: {predicted.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]  # Take the last time step's output\n",
    "        out = self.fc(out)\n",
    "        return torch.sigmoid(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6552417316660285\n",
      "Epoch [2/10], Loss: 0.5373924931883812\n",
      "Epoch [3/10], Loss: 0.4861632794234902\n",
      "Epoch [4/10], Loss: 0.4585159652819857\n",
      "Epoch [5/10], Loss: 0.44248267602175473\n",
      "Epoch [6/10], Loss: 0.4260656095319428\n",
      "Epoch [7/10], Loss: 0.40878328911261635\n",
      "Epoch [8/10], Loss: 0.4100137776811607\n",
      "Epoch [9/10], Loss: 0.38430937006138266\n",
      "Epoch [10/10], Loss: 0.3727330004714895\n",
      "Accuracy: 81.75%\n",
      "Input: aaabbbccc, Label: 1, Predicted: 0.7811494469642639\n",
      "Input: aabbcc, Label: 1, Predicted: 0.6414744257926941\n",
      "Input: cacbb, Label: 0, Predicted: 0.04388630390167236\n",
      "Input: aabbcc, Label: 1, Predicted: 0.6414744257926941\n",
      "Input: ba, Label: 0, Predicted: 0.06045932322740555\n",
      "Input: aaaaaaabbbbbbccccccc, Label: 0, Predicted: 0.8243005871772766\n",
      "Input: aaaaaabbbbbbcccccc, Label: 1, Predicted: 0.8242754936218262\n",
      "Input: aaaaaabbbbbbcccccc, Label: 1, Predicted: 0.8242754936218262\n",
      "Input: aaabbbccc, Label: 1, Predicted: 0.7811494469642639\n",
      "Input: aaaaaabbbbbbcccccc, Label: 1, Predicted: 0.8242754936218262\n"
     ]
    }
   ],
   "source": [
    "# Without Padding\n",
    "add_padding = False\n",
    "batch_size = 1\n",
    "input_size = 3\n",
    "\n",
    "model = LSTMClassifier(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "train_model(model, criterion, optimizer, num_epochs, train_dataset, batch_size)\n",
    "accuracy = evaluate(model, test_dataset, batch_size)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        inputs, labels = test_dataset[i]\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        outputs = model(inputs)\n",
    "        predicted = outputs\n",
    "        inputs_str = ''.join(['a' if c[0] == 1 else 'b' if c[1] == 1 else 'c' if c[2] == 1 else '' for c in inputs[0]])\n",
    "        print(f'Input: {inputs_str}, Label: {int(labels.item())}, Predicted: {predicted.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7655710363388062\n",
      "Epoch [2/10], Loss: 0.7454549372196198\n",
      "Epoch [3/10], Loss: 0.7273312842845917\n",
      "Epoch [4/10], Loss: 0.712902443408966\n",
      "Epoch [5/10], Loss: 0.7040875494480133\n",
      "Epoch [6/10], Loss: 0.6991366815567016\n",
      "Epoch [7/10], Loss: 0.6963172829151154\n",
      "Epoch [8/10], Loss: 0.6948109173774719\n",
      "Epoch [9/10], Loss: 0.6939846813678742\n",
      "Epoch [10/10], Loss: 0.6935606038570404\n",
      "Accuracy: 46.25%\n",
      "Input: aaaaabbbbbbcccccc, Label: 0, Predicted: 0.48046326637268066\n",
      "Input: cabbb, Label: 0, Predicted: 0.4820120930671692\n",
      "Input: bbca, Label: 0, Predicted: 0.48200806975364685\n",
      "Input: b, Label: 0, Predicted: 0.4820096790790558\n",
      "Input: aaaaaabbbbbbcccccc, Label: 1, Predicted: 0.4789251685142517\n"
     ]
    }
   ],
   "source": [
    "# With Padding\n",
    "add_padding = True\n",
    "batch_size = 32\n",
    "input_size = 4\n",
    "\n",
    "model = LSTMClassifier(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "train_model(model, criterion, optimizer, num_epochs, train_dataset_padded, batch_size)\n",
    "accuracy = evaluate(model, test_dataset_padded, batch_size)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(5):\n",
    "        inputs, labels = test_dataset_padded[i]\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        outputs = model(inputs)\n",
    "        predicted = outputs\n",
    "        inputs_str = ''.join(['a' if c[0] == 1 else 'b' if c[1] == 1 else 'c' if c[2] == 1 else '' for c in inputs[0]])\n",
    "        print(f'Input: {inputs_str}, Label: {int(labels.item())}, Predicted: {predicted.item()}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: abcc, Predicted: 0.4820011258125305\n"
     ]
    }
   ],
   "source": [
    "# test both models with a longer example\n",
    "string = 'abcc'\n",
    "inputs = string_to_tensor(string, padding_length=20, add_padding=True).unsqueeze(0)\n",
    "outputs = model(inputs)\n",
    "predicted = outputs\n",
    "print(f'Input: {string}, Predicted: {predicted.item()}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
